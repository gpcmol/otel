apiVersion: opentelemetry.io/v1beta1
kind: OpenTelemetryCollector
metadata:
  name: tailsampling
  namespace: observability
spec:
  replicas: 3
  config:
    receivers:
      otlp:
        protocols:
          grpc:
            endpoint: "${env:MY_POD_IP}:4317"
          http:
            endpoint: "${env:MY_POD_IP}:4318"
            include_metadata: true

    processors:
      memory_limiter:
        check_interval: 5s
        limit_percentage: 70
        spike_limit_percentage: 30
      batch:
        send_batch_max_size: 1000
        timeout: 1s
        send_batch_size: 800
      tail_sampling:
        decision_wait: 30s
        num_traces: 100000 # default 50000
        expected_new_traces_per_sec: 10000 # default 0
        policies:
          - name: trace-status-policy
            type: status_code
            status_code:
              status_codes: ["ERROR"]
          - name: http_status_400_or_higher
            type: numeric_attribute
            numeric_attribute:
              key: http.response.status_code
              min_value: 400
              max_value: 599
          - name: latency_gt_5000ms
            type: latency
            latency:
              threshold_ms: 5000
          - name: rest_traces
            type: probabilistic
            probabilistic:
              sampling_percentage: 1.0

    exporters:
      nop: {}
      debug:
        verbosity: normal
      otlp:
        endpoint: jaeger-collector.demo:4317
        tls:
          insecure: true

    service:
      telemetry:
        logs:
          level: "info"
      pipelines:
        traces:
          receivers: [otlp]
          processors: [memory_limiter,tail_sampling,batch]
          exporters: [debug,otlp]
        metrics:
          exporters: [nop]
          processors: [memory_limiter,batch]
          receivers: [otlp]
          #receivers: [otlp,prometheus]
